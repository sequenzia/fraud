{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1oNXljCTL05HBHvI_l6jashKeeW3OQAJX",
     "timestamp": 1664207167570
    },
    {
     "file_id": "1m6OYsQ1abOwkIg1h4AWpEaO0Z1-m-7xk",
     "timestamp": 1664137601614
    }
   ],
   "collapsed_sections": [
    "YcpuGq29-o6T"
   ],
   "machine_shape": "hm",
   "authorship_tag": "ABX9TyPey5Nr7vKlN8mAp/LpsGC8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "id": "K903b-YefpoR",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJ1NWNO-VIJC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf, numpy as np, pandas as pd, seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tensorflow.keras import layers, losses, models as tf_models, activations, optimizers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import feature_selection as skfs\n",
    "\n",
    "if not os.path.exists(\"plasma\"):\n",
    "    !git clone https://github.com/sequenzia/plasma.git\n",
    "\n",
    "import plasma\n",
    "from plasma import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper Functions"
   ],
   "metadata": {
    "id": "YcpuGq29-o6T",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_corr_fn(data):\n",
    "    plt.figure(figsize=(25,14))\n",
    "    sns.heatmap(data.corr(method='spearman'),annot=True,cmap='YlGnBu')\n",
    "    plt.show()\n",
    "\n",
    "def corr_output_fn(data,cols):\n",
    "    data_corr = data[cols].corr(method='spearman')\n",
    "    data_corr_dict = data_corr.to_dict()\n",
    "\n",
    "    corr_map = {}\n",
    "\n",
    "    for k, v in data_corr_dict.items():\n",
    "        for k2, v2 in v.items():\n",
    "            if k2 != k:\n",
    "                if (k2,k) not in corr_map:\n",
    "                    corr_map[(k,k2)] = v2\n",
    "                    \n",
    "    corr_map = sorted(corr_map.items(), reverse=True, key=lambda kv: kv[1])\n",
    "\n",
    "    plot_corr_fn(data[cols])\n",
    "\n",
    "    print('\\nTop 20 Correlated Features\\n')\n",
    "    for k, v in corr_map[:20]:\n",
    "        print(f'{k}: {v:.7f}')\n",
    "\n",
    "def compare_means(data_1,data_2,alpha,test_type='t'):\n",
    "    \"\"\" \n",
    "    t-test or z-test of means\n",
    "\n",
    "    H0 (null): data_1.mean == data_2.mean\n",
    "    HA (alertantive): data_1.mean > data_2.mean \n",
    "\n",
    "    p-val < alpha reject null\n",
    "\n",
    "    cl = (1-pval)*100\n",
    "\n",
    "    returns data_1_stats,\n",
    "            data_2_stats,\n",
    "            tstats,\n",
    "            pvals,\n",
    "            pvals-alpha,\n",
    "            cls,\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data_1_stats = sm.stats.DescrStatsW(data_1)\n",
    "    data_2_stats = sm.stats.DescrStatsW(data_2)\n",
    "\n",
    "    compare = sm.stats.CompareMeans(data_1_stats,data_2_stats)\n",
    "\n",
    "    if test_type == 'z':\n",
    "        tstats, pvals = compare.ztest_ind('larger')\n",
    "    else:\n",
    "        tstats, pvals, ddf = compare.ttest_ind('larger')\n",
    "\n",
    "    return {\"data_1_stats\":data_1_stats,\n",
    "            \"data_2_stats\":data_2_stats,\n",
    "            \"compare\": compare,\n",
    "            \"tstats\": tstats,\n",
    "            \"pvals\": pvals,\n",
    "            \"pvals_alpha\":pvals-alpha,\n",
    "            \"cls\": (1-pvals)*100}\n",
    "\n",
    "def features_anova_test():\n",
    "    test_stats = skfs.f_classif(data[x_cols],data[y_cols[0]])\n",
    "    p_val = .05\n",
    "\n",
    "    selected_features = {'features': [], 'test_vals':[], 'p_vals':[]}\n",
    "    for i, col in enumerate(x_cols):\n",
    "\n",
    "        cur_test_val = test_stats[0][i]\n",
    "        cur_p_val = test_stats[1][i]\n",
    "\n",
    "        print(f\"Feature: {col} | test_stat = {cur_test_val:.2f} p_val = {cur_p_val:.5f}\")\n",
    "\n",
    "        if cur_p_val < p_val:\n",
    "            print(f\"Reject Null Hypothesis\")\n",
    "        else:\n",
    "            print(f\"Fail to reject Null Hypothesis\")\n",
    "            selected_features['features'].append(col)\n",
    "            selected_features['test_vals'].append(cur_test_val)\n",
    "            selected_features['p_vals'].append(cur_p_val)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(selected_features)\n",
    "\n",
    "def model_metrics(y_true, y_hat, model_type=None):\n",
    "\n",
    "    if model_type:\n",
    "        print(f\"---------------------- {model_type} Model ----------------------\\n\")\n",
    "\n",
    "    target_names = [\"NOT FRAUD\", \"FRAUD\"]    \n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_hat)\n",
    "    precision = precision_score(y_true, y_hat, zero_division=1)\n",
    "    recall = recall_score(y_true, y_hat, zero_division=1)\n",
    "\n",
    "    cls_report = classification_report(y_true, y_hat, digits=5, target_names=target_names, output_dict=False, zero_division=1)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_hat)\n",
    "    cm_ravel = cm.ravel()\n",
    "    cm_groups = {'TN':cm_ravel[0], 'FP':cm_ravel[1], 'FN':cm_ravel[2], 'TP':cm_ravel[3]}\n",
    "\n",
    "    print(f\"{cls_report}\")\n",
    "    # print(\"\\n\")\n",
    "    # print(f\"Accuracy: {accuracy:.5f}\")\n",
    "    # print(f\"Precision: {precision:.5f}\")\n",
    "    # print(f\"Recall: {recall:.5f}\")\n",
    "    # print(\"\\n\")  \n",
    "    print(cm_groups,\"\\n\")\n",
    "    cm_disp = ConfusionMatrixDisplay(cm,display_labels=target_names)\n",
    "    fig = cm_disp.plot()\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\":precision, \"recall\":recall, \"cls_reprt\": cls_report, \"cm\":cm, \"cm_groups\": cm_groups}\n",
    "\n"
   ],
   "metadata": {
    "id": "mbjfyAzX-if9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1664404501091,
     "user_tz": 240,
     "elapsed": 401,
     "user": {
      "displayName": "Stephen Sequenzia",
      "userId": "00124859243818177107"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup"
   ],
   "metadata": {
    "id": "-4dCy0kRJGJg",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "utils.set_options(5)\n",
    "random_state = 42\n",
    "\n",
    "app = plasma.App()\n",
    "data = app.datasets[0]"
   ],
   "metadata": {
    "id": "pubh6AkVJD3u",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1664404497287,
     "user_tz": 240,
     "elapsed": 9271,
     "user": {
      "displayName": "Stephen Sequenzia",
      "userId": "00124859243818177107"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features"
   ],
   "metadata": {
    "id": "j4Eq-70X-w6l",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x_cols = list(data.columns[:-1])\n",
    "y_cols = list(data.columns[-1:])"
   ],
   "metadata": {
    "id": "PTFJflTaV2lq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1664404516439,
     "user_tz": 240,
     "elapsed": 352,
     "user": {
      "displayName": "Stephen Sequenzia",
      "userId": "00124859243818177107"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "selector_anova_tp = skfs.SelectPercentile(skfs.f_classif, percentile=25)\n",
    "selected_features = x_cols\n",
    "# list(selector_anova_tp.fit(data[x_cols],data[y_cols[0]]).get_feature_names_out())\n",
    "print(f\"Selected Features: {selected_features}\")"
   ],
   "metadata": {
    "id": "XSdGVcdY3G_N",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1664404520817,
     "user_tz": 240,
     "elapsed": 3,
     "user": {
      "displayName": "Stephen Sequenzia",
      "userId": "00124859243818177107"
     }
    },
    "outputId": "1a8af7af-07d5-4ee4-cad8-a5c2a753f031",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selected Features: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Unbalanced Classes"
   ],
   "metadata": {
    "id": "pwGypbvUKIQs",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "smote = SMOTE(sampling_strategy='auto')\n",
    "syn_data = pd.concat(smote.fit_resample(data[selected_features],data[y_cols]), axis=1)"
   ],
   "metadata": {
    "id": "nGpBiuJlEbXu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1664404549382,
     "user_tz": 240,
     "elapsed": 661,
     "user": {
      "displayName": "Stephen Sequenzia",
      "userId": "00124859243818177107"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split into Train, Val, Test"
   ],
   "metadata": {
    "id": "fk7BdHt0OpMM",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"------ Main Data ------\")\n",
    "train_data, val_data, test_data  = utils.preprocess_data(data,\n",
    "                                                         cols=[selected_features,y_cols],\n",
    "                                                         split_config=[.8, .1, .1],\n",
    "                                                         pos_split_config=None,\n",
    "                                                         pre_shuffle=False,\n",
    "                                                         to_numpy=False,\n",
    "                                                         random_state=random_state,\n",
    "                                                         debug_on=True)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"------ Positives All Test Data ------\")\n",
    "train_data_pos, val_data_pos, test_data_pos  = utils.preprocess_data(data,\n",
    "                                                                     cols=[selected_features,y_cols],\n",
    "                                                                     split_config=[.8, .1, .1],\n",
    "                                                                     pos_split_config=[0, 0, .1],\n",
    "                                                                     pre_shuffle=False,\n",
    "                                                                     to_numpy=False,\n",
    "                                                                     random_state=random_state,\n",
    "                                                                     debug_on=True)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"------ SMOTE Syn Data ------\")\n",
    "train_syn_data, val_syn_data, test_syn_data = utils.preprocess_data(syn_data,\n",
    "                                                                    cols=[selected_features,y_cols],\n",
    "                                                                    split_config=[.8, .1, .1],\n",
    "                                                                    pos_split_config=None,\n",
    "                                                                    pre_shuffle=False,\n",
    "                                                                    to_numpy=False,\n",
    "                                                                    random_state=random_state,\n",
    "                                                                    debug_on=True)\n",
    "\n",
    "# print(\"------ SMOTE Syn Pos Data ------\")\n",
    "# train_syn_data, val_syn_data, test_syn_data = utils.preprocess_data(syn_data,\n",
    "#                                                                     cols=[selected_features,y_cols],\n",
    "#                                                                     split_config=[.8, .1, .1],\n",
    "#                                                                     pos_split_config=[0, 0, .1],\n",
    "#                                                                     pre_shuffle=False,\n",
    "#                                                                     to_numpy=False,\n",
    "#                                                                     random_state=random_state,\n",
    "#                                                                     debug_on=True)"
   ],
   "metadata": {
    "id": "4RQz3otD5g2r",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1664404554233,
     "user_tz": 240,
     "elapsed": 687,
     "user": {
      "displayName": "Stephen Sequenzia",
      "userId": "00124859243818177107"
     }
    },
    "outputId": "1e3d68c1-bdc9-4bc5-9a02-44954b1b8b25",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------ Main Data ------\n",
      "\n",
      "Train Pos: 417 | 0.85 || Val Pos: 53 | 0.11 || Test Pos: 22 | 0.04\n",
      "\n",
      "Total Records: 284807 | Train: 0.80 | Val: 0.10 | Test: 0.10\n",
      "\n",
      "\n",
      "------ Positives All Test Data ------\n",
      "\n",
      "Train Pos: 0 | 0.00 || Val Pos: 0 | 0.00 || Test Pos: 492 | 1.00\n",
      "\n",
      "Total Records: 284807 | Train: 0.80 | Val: 0.10 | Test: 0.10\n",
      "\n",
      "\n",
      "------ SMOTE Syn Data ------\n",
      "\n",
      "Train Pos: 170589 | 0.60 || Val Pos: 56863 | 0.20 || Test Pos: 56863 | 0.20\n",
      "\n",
      "Total Records: 568630 | Train: 0.80 | Val: 0.10 | Test: 0.10\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "id": "XocXoB3AgVTj",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tress & Forests"
   ],
   "metadata": {
    "id": "gNenfWSDPrLF",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "models = {}\n",
    "\n",
    "def add_model(model_name,model_class,model_args):\n",
    "    models[model_name] = {\"model\":globals()[model_class],\n",
    "                          \"args\": model_args}\n",
    "    return\n",
    "\n",
    "def train_models(dataset):\n",
    "    trained_models = {}\n",
    "\n",
    "    for k, v in models.items():\n",
    "\n",
    "        model = v[\"model\"](**v[\"args\"])\n",
    "\n",
    "        trained_models[k] = model.fit(dataset.x,dataset.y)\n",
    "\n",
    "    return trained_models\n",
    "\n",
    "def evaluate_models(models, dataset):\n",
    "\n",
    "    evaluated_models = {}\n",
    "\n",
    "    for k, v in models.items():\n",
    "\n",
    "        preds = v.predict(dataset.x)\n",
    "        evaluated_models[k] = {'preds': preds, 'metrics': model_metrics(dataset.y, preds, k)}\n",
    "\n",
    "    return evaluate_models"
   ],
   "metadata": {
    "id": "VYWLYEZufsie",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dec_tree_args = {\"criterion\":\"entropy\",\n",
    "                 \"random_state\":random_state}\n",
    "\n",
    "bs_forest_args = {\"criterion\":\"entropy\",\n",
    "                  \"bootstrap\": True,\n",
    "                  \"n_estimators\":100,\n",
    "                  \"n_jobs\":100,\n",
    "                  \"verbose\":0,\n",
    "                  \"random_state\":random_state}\n",
    "\n",
    "full_forest_args = {\"criterion\":\"entropy\",\n",
    "                    \"bootstrap\": False,\n",
    "                    \"n_estimators\":100,\n",
    "                    \"n_jobs\":100,\n",
    "                    \"verbose\":0,\n",
    "                    \"random_state\":random_state}\n",
    "\n",
    "gb_args = {\"n_estimators\":100,\n",
    "           \"learning_rate\":1.0,\n",
    "           \"max_depth\":1,\n",
    "           \"random_state\":random_state}\n",
    "\n",
    "# Decision Tree Classifier\n",
    "add_model(\"dec_tree\", \"DecisionTreeClassifier\", dec_tree_args)\n",
    "\n",
    "# Bootstrapped Random Forest\n",
    "add_model(\"bs_forest\", \"RandomForestClassifier\", bs_forest_args)\n",
    "\n",
    "# Bootstrapped Random Forest\n",
    "add_model(\"full_forest\", \"RandomForestClassifier\", full_forest_args)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "add_model(\"gb\", \"GradientBoostingClassifier\", gb_args)"
   ],
   "metadata": {
    "id": "XA-vGjiqgmfq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trained_models = train_models(train_data)\n",
    "trained_syn_models = train_models(train_syn_data)"
   ],
   "metadata": {
    "id": "qBP6j4yklsl_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "evaluated_models = evaluate_models(trained_models, test_data)"
   ],
   "metadata": {
    "id": "eDyarYRHo5v-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "syn_evaluated_models = evaluate_models(trained_syn_models, test_syn_data)"
   ],
   "metadata": {
    "id": "-AGUQrMCr8kS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Autoencoders"
   ],
   "metadata": {
    "id": "DztjzGUi22tc",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Autoencoder(tf_models.Model):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = tf.keras.Sequential(name=\"encoder\")\n",
    "        \n",
    "        self.encoder.add(layers.Dense(64, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(32, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(16, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(8, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(4, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(2, activation='relu'))\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(name=\"decoder\")\n",
    "\n",
    "        self.decoder.add(layers.Dense(4, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(8, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(16, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(32, activation='relu'))\n",
    "        self.decoder.add(layers.Dense(n_features, activation=activations.sigmoid))\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    def set_threshold(self, x, loss):\n",
    "        recs = self.predict(x)\n",
    "        train_loss = loss(recs, x)\n",
    "        self.threshold = (np.mean(train_loss) + np.std(train_loss))\n",
    "\n",
    "    def rec_predict(self, x, loss, threshold_scaler=1):\n",
    "        recs = self.predict(x)\n",
    "        loss = loss(recs, x)\n",
    "        return tf.math.greater(loss, self.threshold*threshold_scaler), recs, loss\n",
    "\n",
    "ae_model = Autoencoder(len(selected_features))\n",
    "ae_model.compile(optimizer=optimizers.Adam(), loss=losses.MeanSquaredError())"
   ],
   "metadata": {
    "id": "4wpydetK21cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = ae_model.fit(train_data.x, train_data.x,\n",
    "                       epochs=200,\n",
    "                       batch_size=256,\n",
    "                       shuffle=True,\n",
    "                       validation_data=[val_data.x, val_data.x])"
   ],
   "metadata": {
    "id": "F5vDQ_m23bDm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ae_model.set_threshold(train_data.x, losses.mae)"
   ],
   "metadata": {
    "id": "qGPuG0AI6Xxn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ae_preds, ae_recs, ae_loss = ae_model.rec_predict(test_data.x, losses.mae, 2)"
   ],
   "metadata": {
    "id": "wkerSzeJ68wp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ae_metrics = model_metrics(test_data.y, ae_preds, \"AE\")"
   ],
   "metadata": {
    "id": "97W15qde7haX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ae_loss"
   ],
   "metadata": {
    "id": "BGCJmyGB803e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ae_model.threshold"
   ],
   "metadata": {
    "id": "tXLQPNjW85X4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "EO35FrhcFsYe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}